{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import create_engine, MetaData, and Table\n",
    "from sqlalchemy import create_engine, MetaData, Table, func, desc\n",
    "\n",
    "# Create engine: engine\n",
    "engine = create_engine('sqlite:///census.sqlite')\n",
    "connection = engine.connect()\n",
    "\n",
    "# Create a metadata object: metadata\n",
    "metadata = MetaData()\n",
    "\n",
    "# Reflect census table from the engine: census\n",
    "census = Table('census', metadata, autoload=True, autoload_with=engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating Values in a Query\n",
    "\n",
    "Time to do some math on columns on our query. \n",
    " - addition +\n",
    " - subtraction - \n",
    " - division / \n",
    " - modulus % \n",
    "\n",
    "Work differently on different data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(61, 25201), (54, 23503), (55, 21716), (60, 19677), (58, 19526)]\n"
     ]
    }
   ],
   "source": [
    "# Create the statement\n",
    "stmt = select([census.columns.age,\n",
    "              (census.columns.pop2008 \n",
    "               - census.columns.pop2000).label('pop_change')\n",
    "              ])\n",
    "\n",
    "# Group the columns \n",
    "stmt = stmt.group_by(census.columns.age)\n",
    "\n",
    "# Order the columns value according to \"pop_change\"\n",
    "stmt = stmt.order_by(desc('pop_change'))\n",
    "\n",
    "# Limit statement to just return the top 5 results\n",
    "stmt = stmt.limit(5)\n",
    "\n",
    "# Execute the statement\n",
    "results = connection.execute(stmt).fetchall()\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Case Statement\n",
    "\n",
    " - Used to treat data differently based on a condition \n",
    " - Accepts a list of conditions to match and a column to return if the condition matches\n",
    " - The list of conditions ends with an else clause to determine what to do when a record doesn't match any prior conditions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(19465159,)]\n"
     ]
    }
   ],
   "source": [
    "# Import the case statement\n",
    "from sqlalchemy import case\n",
    "\n",
    "# Create the statement\n",
    "stmt = select([\n",
    "    func.sum(\n",
    "        case([\n",
    "            # Check if this statement is true\n",
    "            (census.columns.state == 'New York',\n",
    "             # If is, return the value specify below\n",
    "             census.columns.pop2008)\n",
    "            #If not, then do the next\n",
    "        ], else_= 0))])\n",
    "\n",
    "results = connection.execute(stmt).fetchall()\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cast Statement\n",
    " - When you perform operations and you need to convert a column from one type to another\n",
    " - Useful for converting:\n",
    "   * integers to floats (for division)\n",
    "   * strings to dates and times \n",
    " - Accepts a column or expression and the type to which you want to convert it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(6.426761976501632,)]\n"
     ]
    }
   ],
   "source": [
    "# Import the necessary\n",
    "from sqlalchemy import case, cast, Float\n",
    "\n",
    "# Create the statement\n",
    "stmt = select([\n",
    "    (func.sum(\n",
    "    case([\n",
    "        (census.columns.state == 'New York',\n",
    "        census.columns.pop2008)\n",
    "    ], else_=0)) / \n",
    "    cast(func.sum(census.columns.pop2008),\n",
    "        Float) * 100).label('my_percent')\n",
    "])\n",
    "\n",
    "results = connection.execute(stmt).fetchall()\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we don't convert a number to float when we do division, it will perform floor or integer division and we will get 0 back."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This connection string is going to start with **'mysql+pymysql://'**, indicating which *dialect and driver* you're using to establish the connection. \n",
    "\n",
    "The dialect block is followed by the **'username:password'** combo. \n",
    "\n",
    "Next, you specify the host and port with the following **'@host:port/'**. \n",
    "\n",
    "Finally, you wrap up the connection string with the **'database_name'**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['census', 'state_fact']\n"
     ]
    }
   ],
   "source": [
    "# Import create_engine function\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Create an engine to the census database\n",
    "engine = create_engine('mysql+pymysql://student:datacamp@courses.csrrinzqubik.us-east-1.rds.amazonaws.com:3306/census')\n",
    "\n",
    "# Print the table names\n",
    "print(engine.table_names())\n",
    "\n",
    "# Make a connection\n",
    "connection = engine.connect()\n",
    "\n",
    "# Create a metadata object: metadata\n",
    "metadata = MetaData()\n",
    "\n",
    "# Reflect census table from the engine: census\n",
    "state_fact = Table('state_fact', metadata, autoload=True, autoload_with=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texas:40137\n",
      "California:35406\n",
      "Florida:21954\n",
      "Arizona:14377\n",
      "Georgia:13357\n"
     ]
    }
   ],
   "source": [
    "# Build query to return state names by population difference from 2008 to 2000: stmt\n",
    "stmt = select([census.columns.state,\n",
    "              (census.columns.pop2008 \n",
    "               - census.columns.pop2000).label('pop_change')\n",
    "              ])\n",
    "\n",
    "# Append group by for the state: stmt_grouped\n",
    "stmt_grouped = stmt.group_by(census.columns.state)\n",
    "\n",
    "# Append order by for pop_change descendingly: stmt_ordered\n",
    "stmt_ordered = stmt_grouped.order_by(desc('pop_change'))\n",
    "\n",
    "# Return only 5 results: stmt_top5\n",
    "stmt_top5 = stmt_ordered.limit(5)\n",
    "\n",
    "# Use connection to execute stmt_top5 and fetch all results\n",
    "results = connection.execute(stmt_top5).fetchall()\n",
    "\n",
    "# Print the state and population change for each record\n",
    "for result in results:\n",
    "    print('{}:{}'.format(result.state, result.pop_change))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51.09467432293413\n"
     ]
    }
   ],
   "source": [
    "# import case, cast and Float from sqlalchemy\n",
    "from sqlalchemy import case, cast, Float\n",
    "\n",
    "# Build an expression to calculate female population in 2000\n",
    "female_pop2000 = func.sum(\n",
    "    case([\n",
    "        (census.columns.sex == 'F', census.columns.pop2000)\n",
    "    ], else_=0))\n",
    "\n",
    "# Cast an expression to calculate total population in 2000 to Float\n",
    "total_pop2000 = cast(func.sum(census.columns.pop2000), Float)\n",
    "\n",
    "# Build a query to calculate the percentage of women in 2000: stmt\n",
    "stmt = select([female_pop2000 / total_pop2000* 100])\n",
    "\n",
    "# Execute the query and store the scalar result: percent_female\n",
    "percent_female = connection.execute(stmt).scalar()\n",
    "\n",
    "# Print the percentage\n",
    "print(percent_female)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SQL Relationships\n",
    "\n",
    "Tables can be related to one another via columns that act as a bridge between the tables. \n",
    "\n",
    "## Relationships\n",
    "\n",
    "Allow us to avoid duplicate data\n",
    "\n",
    "Make it wasy to change things in one place\n",
    "\n",
    "Useful to break out information from a table we don't need very often"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(95012, 'IL'), (95012, 'NJ'), (95012, 'ND'), (95012, 'OR'), (95012, 'DC'), (95012, 'WI'), (95012, 'AZ'), (95012, 'AR'), (95012, 'CO'), (95012, 'HI')]\n"
     ]
    }
   ],
   "source": [
    "# Create the statement with both tables\n",
    "stmt = select([census.columns.pop2008,\n",
    "              state_fact.columns.abbreviation])\n",
    "\n",
    "# Execute the statement\n",
    "results = connection.execute(stmt).fetchall()\n",
    "\n",
    "# Print the results\n",
    "print(results[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join\n",
    "\n",
    "To add a relationship that isn't necessarily predefined in a query\n",
    "\n",
    "Accepts a Table and an optional expression that explains how the two tables are related\n",
    "\n",
    "The expression is not needed if the relationship is predefined and available via reflection\n",
    "\n",
    "Commes immediately after the **select()** clause and prior to any **where()**, **order_by()**, **group_by()** clauses\n",
    "\n",
    "## Select_from\n",
    "\n",
    "Used to replace the default, derived FROM clause with a join.\n",
    "\n",
    "Wraps the **join()** clause"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "NoForeignKeysError",
     "evalue": "Can't find any foreign key relationships between 'census' and 'state_fact'.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNoForeignKeysError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-fc68cbcf7b6f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Append the select_from method\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mstmt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstmt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mselect_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcensus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate_fact\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# Where clause to find only specific records\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\anaconda3\\lib\\site-packages\\sqlalchemy\\sql\\selectable.py\u001b[0m in \u001b[0;36mjoin\u001b[1;34m(self, right, onclause, isouter, full)\u001b[0m\n\u001b[0;32m    372\u001b[0m         \"\"\"\n\u001b[0;32m    373\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 374\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mJoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mright\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0monclause\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0misouter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfull\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    375\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    376\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mouterjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mright\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0monclause\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfull\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\anaconda3\\lib\\site-packages\\sqlalchemy\\sql\\selectable.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, left, right, onclause, isouter, full)\u001b[0m\n\u001b[0;32m    737\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    738\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0monclause\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 739\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0monclause\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_match_primaries\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mleft\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mright\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    740\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    741\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0monclause\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0monclause\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\anaconda3\\lib\\site-packages\\sqlalchemy\\sql\\selectable.py\u001b[0m in \u001b[0;36m_match_primaries\u001b[1;34m(self, left, right)\u001b[0m\n\u001b[0;32m    880\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    881\u001b[0m             \u001b[0mleft_right\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 882\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_join_condition\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mleft\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mright\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma_subset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mleft_right\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    883\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    884\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<string>\u001b[0m in \u001b[0;36m_join_condition\u001b[1;34m(cls, a, b, ignore_nonexistent_tables, a_subset, consider_as_foreign_keys)\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\anaconda3\\lib\\site-packages\\sqlalchemy\\util\\deprecations.py\u001b[0m in \u001b[0;36mwarned\u001b[1;34m(fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m    126\u001b[0m                     )\n\u001b[0;32m    127\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 128\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m         \u001b[0mdoc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\anaconda3\\lib\\site-packages\\sqlalchemy\\sql\\selectable.py\u001b[0m in \u001b[0;36m_join_condition\u001b[1;34m(cls, a, b, ignore_nonexistent_tables, a_subset, consider_as_foreign_keys)\u001b[0m\n\u001b[0;32m    945\u001b[0m                 \u001b[1;34m\"Can't find any foreign key relationships \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    946\u001b[0m                 \u001b[1;34m\"between '%s' and '%s'.%s\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 947\u001b[1;33m                 \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdescription\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdescription\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    948\u001b[0m             )\n\u001b[0;32m    949\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNoForeignKeysError\u001b[0m: Can't find any foreign key relationships between 'census' and 'state_fact'."
     ]
    }
   ],
   "source": [
    "# Create the statement\n",
    "stmt = select([func.sum(census.columns.pop2000)])\n",
    "\n",
    "# Append the select_from method \n",
    "stmt = stmt.select_from(census.join(state_fact))\n",
    "\n",
    "# Where clause to find only specific records\n",
    "stmt = stmt.where(state_fact.columns.circuit_court == '10')\n",
    "\n",
    "# Result the connection\n",
    "result = connection.execute(stmt).scalar()\n",
    "\n",
    "# Print the results\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Joining Tables without Predefined Relationship\n",
    "\n",
    "Join accepts a Table and an optional expression that explains how the two tables are related\n",
    " - Same boolean expression as used on the **Where()** clause\n",
    "\n",
    "Will only join rows from each table that can be related between the two columns\n",
    "\n",
    "Avoid joining on columns of different types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20994661\n"
     ]
    }
   ],
   "source": [
    "# Create the statement\n",
    "stmt = select([func.sum(census.columns.pop2000)])\n",
    "\n",
    "# Append a select_from to include the join\n",
    "stmt = stmt.select_from(census.join(state_fact, census.columns.state\n",
    "                                   == state_fact.columns.name))\n",
    "\"\"\"We specify the table and a condition that matches rows\n",
    "based on the state column of the census table and the name \n",
    "of the column state_fact table\"\"\" \n",
    "# Add a where clause to search a specific data type\n",
    "stmt = stmt.where(state_fact.columns.census_division_name\n",
    "                 == 'East South Central')\n",
    "\n",
    "# Execute the Query\n",
    "result = connection.execute(stmt).scalar()\n",
    "\n",
    "# Print the results\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have two tables that already have an established relationship, you can automatically use that relationship by just adding the columns we want from each table to the select statement. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pop2000 89600\n",
      "abbreviation IL\n"
     ]
    }
   ],
   "source": [
    "# Build a statement to join census and state_fact tables: stmt\n",
    "stmt = select([census.columns.pop2000, state_fact.columns.abbreviation])\n",
    "\n",
    "# Execute the statement and get the first result: result\n",
    "result = connection.execute(stmt).first()\n",
    "\n",
    "# Loop over the keys in the result object and print the key and value\n",
    "for key in result.keys():\n",
    "    print(key, getattr(result, key))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you aren't selecting columns from both tables or the two tables don't have a defined relationship, you can still use the **.join()** method on a table to join it with another table and get extra data related to our query. \n",
    "\n",
    "The **join()** takes the table object you want to join in as the first argument and a condition that indicates how the tables are related to the second argument. \n",
    "\n",
    "Finally, you use the **.select_from()** method on the select statement to wrap the join clause."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state Illinois\n",
      "sex M\n",
      "age 0\n",
      "pop2000 89600\n",
      "pop2008 95012\n",
      "id 13\n",
      "name Illinois\n",
      "abbreviation IL\n",
      "country USA\n",
      "type state\n",
      "sort 10\n",
      "status current\n",
      "occupied occupied\n",
      "notes \n",
      "fips_state 17\n",
      "assoc_press Ill.\n",
      "standard_federal_region V\n",
      "census_region 2\n",
      "census_region_name Midwest\n",
      "census_division 3\n",
      "census_division_name East North Central\n",
      "circuit_court 7\n"
     ]
    }
   ],
   "source": [
    "# Build a statement to select the census and state_fact tables: stmt\n",
    "stmt = select([census, state_fact])\n",
    "\n",
    "# Add a select_from clause that wraps a join for the census and state_fact\n",
    "# tables where the census state column and state_fact name column match\n",
    "stmt_join = stmt.select_from(\n",
    "    census.join(state_fact, census.columns.state == state_fact.columns.name))\n",
    "\n",
    "# Execute the statement and get the first result: result\n",
    "result = connection.execute(stmt_join).first()\n",
    "\n",
    "# Loop over the keys in the result object and print the key and value\n",
    "for key in result.keys():\n",
    "    print(key, getattr(result, key))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Alabama', Decimal('4681422'), 'East South Central')\n",
      "('Alaska', Decimal('664546'), 'Pacific')\n",
      "('Arizona', Decimal('10698743'), 'Mountain')\n",
      "('Arkansas', Decimal('4343608'), 'West South Central')\n",
      "('California', Decimal('56952946'), 'Pacific')\n",
      "('Colorado', Decimal('7474086'), 'Mountain')\n",
      "('Connecticut', Decimal('3727540'), 'New England')\n",
      "('Delaware', Decimal('869221'), 'South Atlantic')\n",
      "('Florida', Decimal('20339477'), 'South Atlantic')\n",
      "('Georgia', Decimal('9622508'), 'South Atlantic')\n",
      "('Hawaii', Decimal('1250676'), 'Pacific')\n",
      "('Idaho', Decimal('1518914'), 'Mountain')\n",
      "('Illinois', Decimal('16274391'), 'East North Central')\n",
      "('Indiana', Decimal('7378168'), 'East North Central')\n",
      "('Iowa', Decimal('3000490'), 'West North Central')\n",
      "('Kansas', Decimal('4045759'), 'West North Central')\n",
      "('Kentucky', Decimal('4525061'), 'East South Central')\n",
      "('Louisiana', Decimal('5183486'), 'West South Central')\n",
      "('Maine', Decimal('2018932'), 'New England')\n",
      "('Maryland', Decimal('7246747'), 'South Atlantic')\n",
      "('Massachusetts', Decimal('6492024'), 'New England')\n",
      "('Michigan', Decimal('14154883'), 'East North Central')\n",
      "('Minnesota', Decimal('6922744'), 'West North Central')\n",
      "('Mississippi', Decimal('4560123'), 'East South Central')\n",
      "('Missouri', Decimal('7836564'), 'West North Central')\n",
      "('Montana', Decimal('1172060'), 'Mountain')\n",
      "('Nebraska', Decimal('2348009'), 'West North Central')\n",
      "('Nevada', Decimal('3925294'), 'Mountain')\n",
      "('New Hampshire', Decimal('1949141'), 'New England')\n",
      "('New Jersey', Decimal('8670204'), 'Mid-Atlantic')\n",
      "('New Mexico', Decimal('3263613'), 'Mountain')\n",
      "('New York', Decimal('26837888'), 'Mid-Atlantic')\n",
      "('North Carolina', Decimal('9121606'), 'South Atlantic')\n",
      "('North Dakota', Decimal('634282'), 'West North Central')\n",
      "('Ohio', Decimal('16565266'), 'East North Central')\n",
      "('Oklahoma', Decimal('4736015'), 'West South Central')\n",
      "('Oregon', Decimal('4901890'), 'Pacific')\n",
      "('Pennsylvania', Decimal('17277878'), 'Mid-Atlantic')\n",
      "('Rhode Island', Decimal('1096276'), 'New England')\n",
      "('South Carolina', Decimal('4438870'), 'South Atlantic')\n",
      "('South Dakota', Decimal('800997'), 'West North Central')\n",
      "('Tennessee', Decimal('8524299'), 'East South Central')\n",
      "('Texas', Decimal('39829923'), 'West South Central')\n",
      "('Utah', Decimal('2730919'), 'Mountain')\n",
      "('Vermont', Decimal('820523'), 'New England')\n",
      "('Virginia', Decimal('9593860'), 'South Atlantic')\n",
      "('Washington', Decimal('8080837'), 'Pacific')\n",
      "('West Virginia', Decimal('1812879'), 'South Atlantic')\n",
      "('Wisconsin', Decimal('7518844'), 'East North Central')\n",
      "('Wyoming', Decimal('653500'), 'Mountain')\n"
     ]
    }
   ],
   "source": [
    "# Build a statement to select the state, sum of 2008 population and census\n",
    "# division name: stmt\n",
    "stmt = select([\n",
    "    census.columns.state,\n",
    "    func.sum(census.columns.pop2008),\n",
    "    state_fact.columns.census_division_name\n",
    "])\n",
    "\n",
    "# Append select_from to join the census and state_fact tables by the census state and state_fact name columns\n",
    "stmt_joined = stmt.select_from(\n",
    "    census.join(state_fact, census.columns.state == state_fact.columns.name)\n",
    ")\n",
    "\n",
    "# Append a group by for the state_fact name column\n",
    "stmt_grouped = stmt_joined.group_by(state_fact.columns.name)\n",
    "\n",
    "# Execute the statement and get the results: results\n",
    "results = connection.execute(stmt_grouped).fetchall()\n",
    "\n",
    "# Loop over the results object and print each record.\n",
    "for record in results:\n",
    "    print(record)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with Hierarchical Tables\n",
    "\n",
    "There are also tables that join with themselves\n",
    " - Called **self-referential** or **hierarchical**\n",
    " \n",
    "Contain a relationship with themselves\n",
    "\n",
    "Commonly found in:\n",
    " - Store organizational charts\n",
    " - Geographic data\n",
    " - Networks\n",
    " - Relationships graphs\n",
    "\n",
    "The **alias()** method allows us to create a way to refer to the same table with two unique names. \n",
    " - Creates a unique reference that we can use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import create_engine, MetaData, and Table\n",
    "from sqlalchemy import create_engine, MetaData, Table, func, desc\n",
    "\n",
    "# Create engine: engine\n",
    "engine = create_engine('sqlite:///employees.sqlite')\n",
    "connection = engine.connect()\n",
    "\n",
    "# Create a metadata object: metadata\n",
    "metadata = MetaData()\n",
    "\n",
    "# Reflect census table from the engine: census\n",
    "employees = Table('employees', metadata, autoload=True, autoload_with=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('FILLMORE', 'GRANT'), ('FILLMORE', 'ADAMS'), ('FILLMORE', 'MONROE'), ('GARFIELD', 'JOHNSON'), ('GARFIELD', 'LINCOLN'), ('GARFIELD', 'POLK'), ('GARFIELD', 'WASHINGTON'), ('HARDING', 'TAFT'), ('HARDING', 'HOOVER'), ('JACKSON', 'HARDING'), ('JACKSON', 'GARFIELD'), ('JACKSON', 'FILLMORE'), ('JACKSON', 'ROOSEVELT')]\n"
     ]
    }
   ],
   "source": [
    "managers = employees.alias()\n",
    "\n",
    "# Create the statement\n",
    "stmt = select([\n",
    "    managers.columns.name.label('manager'),\n",
    "    employees.columns.name.label('employee')\n",
    "])\n",
    "\n",
    "# Join the tables Manager and Employee\n",
    "stmt = stmt.select_from(\n",
    "    employees.join(managers, managers.columns.id == \n",
    "                   employees.columns.mgr))\n",
    "\n",
    "# Order the columns by the manager's name\n",
    "stmt = stmt.order_by(managers.columns.name)\n",
    "\n",
    "# Execute the statement\n",
    "result = connection.execute(stmt).fetchall()\n",
    "\n",
    "# Print the result\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hierarchical tables can get tricky when performing **group_by()** or using **func**.\n",
    "\n",
    "It's important to think of it as if it were two different tables. \n",
    "\n",
    "It's important to target **group_by()** at the right alias. \n",
    "\n",
    "Be careful with that you perform functions on \n",
    "\n",
    "If you don't find yourself using both the alias and the table name for a query, don't create the alias at all. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "manager",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\anaconda3\\lib\\site-packages\\sqlalchemy\\util\\_collections.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    209\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 210\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    211\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'manager'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-50-d08f14b1ce6b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m     employees.join(\n\u001b[0;32m     10\u001b[0m     \u001b[0mmanagers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmanagers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mid\u001b[0m \u001b[1;33m==\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     employees.columns.manager))\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mstmt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstmt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroup_by\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmanagers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\anaconda3\\lib\\site-packages\\sqlalchemy\\util\\_collections.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 212\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    213\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    214\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__contains__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: manager"
     ]
    }
   ],
   "source": [
    "managers = employees.alias()\n",
    "\n",
    "stmt = select([\n",
    "    managers.columns.name,\n",
    "    func.sum(employees.columns.sal)\n",
    "])\n",
    "\n",
    "stmt = stmt.select_from(\n",
    "    employees.join(\n",
    "    managers, managers.columns.id ==\n",
    "    employees.columns.manager))\n",
    "\n",
    "stmt = stmt.group_by(managers.columns.name)\n",
    "\n",
    "print(connection.execute(stmt).fetchall())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('FILLMORE', 'GRANT')\n",
      "('FILLMORE', 'ADAMS')\n",
      "('FILLMORE', 'MONROE')\n",
      "('GARFIELD', 'JOHNSON')\n",
      "('GARFIELD', 'LINCOLN')\n",
      "('GARFIELD', 'POLK')\n",
      "('GARFIELD', 'WASHINGTON')\n",
      "('HARDING', 'TAFT')\n",
      "('HARDING', 'HOOVER')\n",
      "('JACKSON', 'HARDING')\n",
      "('JACKSON', 'GARFIELD')\n",
      "('JACKSON', 'FILLMORE')\n",
      "('JACKSON', 'ROOSEVELT')\n"
     ]
    }
   ],
   "source": [
    "# Make an alias of the employees table: managers\n",
    "managers = employees.alias()\n",
    "\n",
    "# Build a query to select names of managers and their employees: stmt\n",
    "stmt = select(\n",
    "    [managers.columns.name.label('manager'),\n",
    "     employees.columns.name.label('employee')]\n",
    ")\n",
    "\n",
    "# Match managers id with employees mgr: stmt_matched\n",
    "stmt_matched = stmt.where(managers.columns.id == employees.columns.mgr)\n",
    "\n",
    "# Order the statement by the managers name: stmt_ordered\n",
    "stmt_ordered = stmt_matched.order_by(managers.columns.name)\n",
    "\n",
    "# Execute statement: results\n",
    "results = connection.execute(stmt_ordered).fetchall()\n",
    "\n",
    "# Print records\n",
    "for record in results:\n",
    "    print(record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('FILLMORE', 3)\n",
      "('GARFIELD', 4)\n",
      "('HARDING', 2)\n",
      "('JACKSON', 4)\n"
     ]
    }
   ],
   "source": [
    "# Make an alias of the employees table: managers\n",
    "managers = employees.alias()\n",
    "\n",
    "# Build a query to select names of managers and counts of their employees: stmt\n",
    "stmt = select([managers.columns.name, func.count(employees.columns.id)])\n",
    "\n",
    "# Append a where clause that ensures the manager id and employee mgr are equal\n",
    "stmt_matched = stmt.where(managers.columns.id == employees.columns.mgr)\n",
    "\n",
    "# Group by Managers Name\n",
    "stmt_grouped = stmt_matched.group_by(managers.columns.name)\n",
    "\n",
    "# Execute statement: results\n",
    "results = connection.execute(stmt_grouped).fetchall()\n",
    "\n",
    "# print manager\n",
    "for record in results:\n",
    "    print(record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table('employees', MetaData(bind=None), Column('id', INTEGER(), table=<employees>, primary_key=True, nullable=False), Column('name', VARCHAR(length=20), table=<employees>), Column('job', VARCHAR(length=20), table=<employees>), Column('mgr', INTEGER(), table=<employees>), Column('hiredate', DATETIME(), table=<employees>), Column('sal', NUMERIC(precision=7, scale=2), table=<employees>), Column('comm', NUMERIC(precision=7, scale=2), table=<employees>), Column('dept', INTEGER(), table=<employees>), schema=None)\n"
     ]
    }
   ],
   "source": [
    "print(repr(employees))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handling Large ResultSets\n",
    "\n",
    "Dealing with large result sets can be problematic, as we might run out of memory or disk space to store the results. \n",
    "\n",
    "**fetchmany()** - let us specify how many rows we want to act upon\n",
    " - We can loop over it\n",
    " - It returns an empty lsit where there are no more records\n",
    " - We have to close the ResultProxy afterwards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'more_results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-57-1bc3868ff499>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Start a while loop checking for more results\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mwhile\u001b[0m \u001b[0mmore_results\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[1;31m# Fetch the first 50 results from the ResultProxy: partial_results\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mpartial_results\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresults_proxy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetchmany\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'more_results' is not defined"
     ]
    }
   ],
   "source": [
    "# Start a while loop checking for more results\n",
    "while more_results:\n",
    "    # Fetch the first 50 results from the ResultProxy: partial_results\n",
    "    partial_results = results_proxy.fetchmany(50)\n",
    "\n",
    "    # if empty list, set more_results to False\n",
    "    if partial_results == []:\n",
    "        more_results = False\n",
    "\n",
    "    # Loop over the fetched records and increment the count for the state\n",
    "    for row in partial_results:\n",
    "        if row.state in state_count:\n",
    "            state_count[row.state] += 1\n",
    "        else:\n",
    "            state_count[row.state] = 1\n",
    "\n",
    "# Close the ResultProxy, and thus the connection\n",
    "results_proxy.close()\n",
    "\n",
    "# Print the count by state\n",
    "print(state_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
